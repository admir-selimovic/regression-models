{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9eTqHKTtz73"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data class\n",
        "class Data(Dataset):\n",
        "    \"\"\"A custom dataset class for generating synthetic data points with labels.\"\"\"\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, train=True):\n",
        "        \"\"\"Initialize the dataset with data points and labels.\n",
        "\n",
        "        Args:\n",
        "            train (bool, optional): Determines whether to create the training dataset with outliers. Default is True.\n",
        "        \"\"\"\n",
        "        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
        "        self.f = -3 * self.x + 1\n",
        "        self.y = self.f + 0.1 * torch.randn(self.x.size())\n",
        "        self.len = self.x.shape[0]\n",
        "\n",
        "        # Introduce outliers for the training dataset\n",
        "        if train:\n",
        "            self.y[0] = 0\n",
        "            self.y[50:55] = 20\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # Getter\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get a single data point and its label.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the data point.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the data point and its label.\n",
        "        \"\"\"\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    # Get Length\n",
        "    def __len__(self):\n",
        "        \"\"\"Get the length of the dataset.\"\"\"\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "m-fvw-tIudXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training dataset and validation dataset\n",
        "train_data = Data()\n",
        "val_data = Data(train=False)\n",
        "\n",
        "# Plot training points\n",
        "plt.plot(train_data.x.numpy(), train_data.y.numpy(), 'xr', label=\"training data\")\n",
        "plt.plot(train_data.x.numpy(), train_data.f.numpy(), label=\"true function\")\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EIa-lKuWugIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Linear Regression Class\n",
        "class linear_regression(nn.Module):\n",
        "    \"\"\"A custom linear regression model class.\"\"\"\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \"\"\"Initialize the linear regression model.\"\"\"\n",
        "        super(linear_regression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the model.\"\"\"\n",
        "        yhat = self.linear(x)\n",
        "        return yhat"
      ],
      "metadata": {
        "id": "hSuAo0Nnugqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MSELoss function and DataLoader\n",
        "criterion = nn.MSELoss()\n",
        "trainloader = DataLoader(dataset=train_data, batch_size=1)"
      ],
      "metadata": {
        "id": "px7ZW5x9ukhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train model function and train the model\n",
        "def train_model_with_lr(iter, lr_list):\n",
        "    \"\"\"\n",
        "    Train the model using different learning rates and store results.\n",
        "\n",
        "    Args:\n",
        "    iter (int): Number of iterations for training.\n",
        "    lr_list (list): List of learning rates to try.\n",
        "    \"\"\"\n",
        "    global MODELS\n",
        "    MODELS = []\n",
        "\n",
        "    for i, lr in enumerate(lr_list):\n",
        "        model = linear_regression(1, 1)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(iter):\n",
        "            for x, y in trainloader:\n",
        "                yhat = model(x)\n",
        "                loss = criterion(yhat, y)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # Calculate training loss\n",
        "        Yhat_train = model(train_data.x)\n",
        "        train_loss = criterion(Yhat_train, train_data.y)\n",
        "        train_error[i] = train_loss.item()\n",
        "\n",
        "        # Calculate validation loss\n",
        "        Yhat_val = model(val_data.x)\n",
        "        val_loss = criterion(Yhat_val, val_data.y)\n",
        "        validation_error[i] = val_loss.item()\n",
        "        MODELS.append(model)\n",
        "\n",
        "# Define learning rates\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "train_error = torch.zeros(len(learning_rates))\n",
        "validation_error = torch.zeros(len(learning_rates))\n",
        "\n",
        "# Train models with different learning rates\n",
        "train_model_with_lr(10, learning_rates)"
      ],
      "metadata": {
        "id": "PrhnOkLnurLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss and validation loss\n",
        "plt.semilogx(np.array(learning_rates), train_error.numpy(), label='training loss/total Loss')\n",
        "plt.semilogx(np.array(learning_rates), validation_error.numpy(), label='validation cost/total Loss')\n",
        "plt.ylabel('Cost/Total Loss')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mNCu53-tuskZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the predictions\n",
        "for model, learning_rate in zip(MODELS, learning_rates):\n",
        "    yhat = model(val_data.x)\n",
        "    plt.plot(val_data.x.numpy(), yhat.detach().numpy(), label='lr:' + str(learning_rate))\n",
        "\n",
        "plt.plot(val_data.x.numpy(), val_data.f.numpy(), 'or', label='validation data')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wm8-DaBquvWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
